---
title: "duckplyr into - RforLunch"
author: "John Little"
format: html
---

## Load library packages

{duckplyr} is designed to be a drop-in replacement for {dplyr}, using the same function names and interfaces, but with DuckDB as the backend for faster performance. It's best to avoide loading {tidyverse} or {dplyr} packages directly; {duckplyr} will use optimized versions of its functions and fall back to the original {dplyr} functions when needed.

```{r}
library(duckplyr)
library(conflicted)
library(nycflights13)

conflict_prefer("filter", "dplyr", quiet = TRUE)
```

## Import data

`duckplyr::flights_df()` calls a variant of `nycflights13::flights` that is compatible with duckplyr

```{r}
flights_df() #|> 
  # count() |>
  # mutate(n = scales::comma(n))
```

Use standard {tidyverse} syntax.

```{r}

out_df <- flights_df() |>
  filter(!is.na(arr_delay), !is.na(dep_delay)) |> 
  mutate(inflight_delay = arr_delay - dep_delay) |>
  summarize(
    .by = c(year, month),
    mean_inflight_delay = mean(inflight_delay),
    median_inflight_delay = median(inflight_delay),
  ) |>
  filter(month <= 6)

out_df
```

```{r}
class(out_df)
```

```{r}
flights_df() |>
  summarize(
    .by = origin,
    dest = paste(sort(unique(dest)), collapse = " ")
  )
```

## Load more data

This time, let's import some parquet files directly from the internet. First, let's set up a tibble of URLs.

```{r}
year <- 2022:2024
base_url <- "https://blobs.duckdb.org/flight-data-partitioned/"
files <- paste0("Year=", year, "/data_0.parquet")
urls <- paste0(base_url, files)
tibble(urls)
```

DuckDB can take [extensions](https://duckdb.org/docs/stable/extensions/overview.html) to extend DuckDB functionality. Below we allow the [reading/writing remote files via the HTTPS](https://duckdb.org/docs/stable/extensions/httpfs/overview) protocol.

```{r}
db_exec("INSTALL httpfs")
db_exec("LOAD httpfs")
```

Now we can import parquet files remotely. Parquet files are a columnar storage format that is more efficient than CSV and well-suited for big data applications and analysis. These particular files are demo files stored at the DuckDB site; retrievable remotely via HTTPS.

```{r}
flights <- read_parquet_duckdb(urls)
```

DuckDB is a columnar database management system that can efficiently work with tabular data. When using DuckDB with R (particularly with the {duckplyr} package), what's happening is:

-   DuckDB operates as an in-process analytical database engine
-   Operations are translated into SQL and executed by the DuckDB engine
-   This happens transparently, so you can use familiar {dplyr} syntax

When you use {duckplyr}, your operations are performed using DuckDB's engine rather than R's memory, which can be dramatically faster for large datasets, while still maintaining the familiar {dplyr} interface.

The result objects from DuckDB operations can be materialized as regular R data frames or tibbles when needed, but the intermediate operations happen within the DuckDB engine for efficiency. This means, DuckDB objects are not traditional data frames, but allow for deferred computation until the compute is necessary. Thge {duckplyr} data frame behaves as a regular data frame, but has key under-the-hood differences. One difference is *lazy materialization*, (i.e. deferred computation) for optimized compute. The other is **prudence** of showing large data which can result in memory problems. Prudence has three levels (*lavish, stingy, and thrifty*) that we'll demonstrate later.

```{r}
class(flights)
```

Because data can be large, it's often useful to avoid displaying the full data. Tactical use of the `head()` function can easily LIMIT the size of the data. The opposite technique is to use the COLLECT function by converting the input into a tibble (i.e. materializing the lazy operation.) Keep in mind that `collect()` can lead to memory problems if not use **prudently**.

```{r}
flights |> 
  head()
```

Explain is a {dplyr} function that can help you see the structure of a {duckplyr object}

```{r}
flights |> 
  explain()
```

Below is a more complicated example of using {dplyr} functions in a {duckplyr} context

```{r}
mean_arr_delay_ewr <- flights_df() |>
  duckplyr::as_duckdb_tibble(prudence = "lavish") |>
  filter(origin == "EWR", !is.na(arr_delay)) |>
  summarize(
    .by = month,
    mean_arr_delay = mean(arr_delay),
    min_arr_delay = min(arr_delay),
    max_arr_delay = max(arr_delay),
    median_arr_delay = median(arr_delay),
  )

mean_arr_delay_ewr
```

Have a look under the hood.

```{r}
flights |> explain()
mean_arr_delay_ewr |> explain()

class(flights)
class(mean_arr_delay_ewr)
```

The `explain()` function, does not give an exact row count, but it does give an idea of how the {duckplyr} object is formatted. An alternative to determining size is to use the `count()` function. (This may not work in the context of very big data.)

```{r}
flights |> 
  count() |> 
  mutate(pretty_n = scales::comma(n))
```

Another example and a `system.time()` calculation.

```{r}
out <-
  flights |>
  mutate(InFlightDelay = ArrDelay - DepDelay) |>
  summarize(
    .by = c(Year, Month),
    MeanInFlightDelay = mean(InFlightDelay, na.rm = TRUE),
    MedianInFlightDelay = median(InFlightDelay, na.rm = TRUE),
  ) |>
  filter(Year < 2024)

out |>
  print() |>
  system.time()
```

```{r}
out |>
  explain()
```

How many of our function calls wer {duckplyr} and how many times did it fall back to {dplyr}?

```{r}
stats_show()
```
